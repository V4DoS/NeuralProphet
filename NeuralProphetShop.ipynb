{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2117a097-4a52-45b6-8ab8-d708caf8ae30",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e56f9-3f80-4ca5-a535-7f6bbca41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                         #Включаем видеокарту если есть\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Используется устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e1055-9bc4-4b8b-9314-bc3449378c31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid search hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d39fc0-226e-4bfc-ba8d-2934e760c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                         #+ 2 доп.гиперпараметра\n",
    "from neuralprophet import NeuralProphet\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed  # Для параллельных вычислений\n",
    "\n",
    "# Блок 1: Загрузка данных и предварительная обработка\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "data = data[(data['Дата'] >= '2022-01-01')]\n",
    "\n",
    "# Подготовка данных для модели NeuralProphet\n",
    "data = data.rename(columns={'Дата': 'ds', 'Номер Магазина': 'store', '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Удаление дубликатов по колонке 'ds' (даты) для каждого магазина\n",
    "data = data.drop_duplicates(subset=['store', 'ds'])\n",
    "\n",
    "# Блок 2: Определение сетки гиперпараметров\n",
    "n_changepoints = [5, 10, 20, 30]\n",
    "changepoints_range = [0.75, 0.85, 0.95]\n",
    "yearly_seasonality = [True, 5, 10]\n",
    "weekly_seasonality = [True, 3, 6]\n",
    "seasonality_mode = ['additive', 'multiplicative']\n",
    "trend_reg = [0.4]\n",
    "seasonality_reg = [0.4]\n",
    "\n",
    "# Минимальное количество данных для расчета гиперпараметров (например, 30 дней)\n",
    "min_data_points = 60\n",
    "\n",
    "# Функция для расчета гиперпараметров для каждого магазина\n",
    "def calculate_best_params_for_store(store_id, store_data):\n",
    "    if len(store_data) < min_data_points:\n",
    "        print(f\"Пропуск магазина {store_id}: недостаточно данных ({len(store_data)} строк)\")\n",
    "        return None\n",
    "    \n",
    "    best_accuracy = float('inf')  # Начальная высокая точность (для MAE)\n",
    "    best_params = {}\n",
    "    \n",
    "    # Разделение данных на тренировочные и тестовые\n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data = store_data[:train_size]\n",
    "    test_data = store_data[train_size:]\n",
    "    \n",
    "    # Перебор всех комбинаций гиперпараметров\n",
    "    for n_cp, cp_range, yearly_seas, weekly_seas, seas_mode, t_reg, s_reg in product(\n",
    "        n_changepoints, changepoints_range, yearly_seasonality, weekly_seasonality, seasonality_mode, trend_reg, seasonality_reg\n",
    "    ):\n",
    "        # Создание и обучение модели\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=n_cp,\n",
    "            changepoints_range=cp_range,\n",
    "            yearly_seasonality=yearly_seas,\n",
    "            weekly_seasonality=weekly_seas,\n",
    "            seasonality_mode=seas_mode,\n",
    "            trend_reg=t_reg,\n",
    "            seasonality_reg=s_reg\n",
    "            #device=device\n",
    "        )\n",
    "        \n",
    "        model.fit(train_data, freq='D')\n",
    "        \n",
    "        # Прогнозирование на тестовых данных\n",
    "        future = model.make_future_dataframe(test_data, periods=len(test_data))\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Оценка точности\n",
    "        y_true = test_data['y'].values\n",
    "        y_pred = forecast['yhat1'].values[:len(test_data)]\n",
    "        accuracy = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        # Сравнение точности и обновление лучших параметров\n",
    "        if accuracy < best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {\n",
    "                'store': store_id,\n",
    "                'n_changepoints': n_cp,\n",
    "                'changepoints_range': cp_range,\n",
    "                'yearly_seasonality': yearly_seas,\n",
    "                'weekly_seasonality': weekly_seas,\n",
    "                'seasonality_mode': seas_mode,\n",
    "                'trend_reg': t_reg,\n",
    "                'seasonality_reg': s_reg\n",
    "            }\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# Получаем список всех магазинов\n",
    "stores = data['store'].unique()\n",
    "\n",
    "# Параллельный расчет для всех магазинов\n",
    "best_params_list = Parallel(n_jobs=-1)(\n",
    "    delayed(calculate_best_params_for_store)(store_id, data[data['store'] == store_id][['ds', 'y']]) \n",
    "    for store_id in stores\n",
    ")\n",
    "\n",
    "# Убираем None значения (если магазин был пропущен из-за недостатка данных)\n",
    "best_params_list = [params for params in best_params_list if params is not None]\n",
    "\n",
    "# Блок 3: Сохранение гиперпараметров для всех магазинов в Excel файл\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_model_params_all_stores+.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f49447-226d-4499-a847-839490ca4257",
   "metadata": {},
   "source": [
    "# Bayes optimization hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77f556-fda5-45e5-a61f-5d927980e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "data = data[(data['Дата'] >= '2023-01-01')]\n",
    "\n",
    "# Переименование колонок\n",
    "data = data.rename(columns={'Дата': 'ds', 'Номер Магазина': 'store', '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data = data.drop_duplicates(subset=['store', 'ds'])\n",
    "\n",
    "# Минимальное количество данных для расчета гиперпараметров\n",
    "min_data_points = 60\n",
    "\n",
    "# Функция для оптимизации гиперпараметров\n",
    "def objective(trial, store_data):\n",
    "    if len(store_data) < min_data_points:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Выбор гиперпараметров\n",
    "    n_changepoints = trial.suggest_int('n_changepoints', 5, 30)  # Должно быть int, а не float\n",
    "    changepoints_range = trial.suggest_float('changepoints_range', 0.75, 0.95)\n",
    "    yearly_seasonality = trial.suggest_int('yearly_seasonality', 1, 20)  # Должно быть int, а не float\n",
    "    weekly_seasonality = trial.suggest_int('weekly_seasonality', 1, 7)  # Должно быть int, а не float\n",
    "    seasonality_mode = trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative'])\n",
    "    trend_reg = trial.suggest_float('trend_reg', 0.1, 1.0)\n",
    "    seasonality_reg = trial.suggest_float('seasonality_reg', 0.1, 1.0)\n",
    "    growth = trial.suggest_categorical('growth', ['linear', 'discontinuous'])\n",
    "    n_lags = trial.suggest_int('n_lags', 0, 30)\n",
    "    ar_reg = trial.suggest_float('ar_reg', 0.0, 1.0)  # Исправлено название параметра\n",
    "\n",
    "    # Разделение данных на train/test\n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data, test_data = store_data[:train_size], store_data[train_size:]\n",
    "\n",
    "    # Обучение модели\n",
    "    model = NeuralProphet(\n",
    "        n_changepoints=n_changepoints, changepoints_range=changepoints_range,\n",
    "        yearly_seasonality=yearly_seasonality, weekly_seasonality=weekly_seasonality,\n",
    "        seasonality_mode=seasonality_mode, trend_reg=trend_reg, seasonality_reg=seasonality_reg,\n",
    "        growth=growth, n_lags=n_lags, ar_reg=ar_reg  # Исправлен параметр\n",
    "    )\n",
    "    model.fit(train_data, freq='D')\n",
    "\n",
    "    # Генерация будущих дат (исправлено)\n",
    "    future = model.make_future_dataframe(df=train_data, periods=len(test_data))\n",
    "\n",
    "    # Получение прогноза\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Проверка длины прогноза\n",
    "    if len(forecast) < len(test_data):\n",
    "        return float('inf')  # Если прогноз короче тестовой выборки, считаем ошибку бесконечной\n",
    "    \n",
    "    # Оценка качества модели\n",
    "    y_true, y_pred = test_data['y'].values, forecast['yhat1'].values[:len(test_data)]\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Функция для оптимизации гиперпараметров каждого магазина\n",
    "def optimize_for_store(store_id, store_data):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, store_data), n_trials=50)              # Количество итераций\n",
    "    best_params = study.best_params\n",
    "    best_params['store'] = store_id\n",
    "    return best_params\n",
    "\n",
    "# Получение списка магазинов\n",
    "stores = data['store'].unique()\n",
    "\n",
    "# Параллельный запуск оптимизации\n",
    "best_params_list = Parallel(n_jobs=-1)(\n",
    "    delayed(optimize_for_store)(store_id, data[data['store'] == store_id][['ds', 'y']]) for store_id in stores\n",
    ")\n",
    "\n",
    "# Сохранение лучших параметров\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_model_params_bo.xlsx', index=False)\n",
    "\n",
    "print(\"Оптимизация завершена! Результаты сохранены.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2082b-4a5b-4956-9234-981fcb17694f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b315fb1-b8b7-4fe8-aa09-80a9fad0f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52488 комбинаций перебора.для 1 магазина при условии паралельных вычислений 16 комбинаций в минуту \n",
    "# на процесооре будет считать 54 часа...\n",
    "param_grid = {\n",
    "    'n_changepoints': [5, 10, 20],  # Количество точек изменения тренда\n",
    "    'changepoints_range': [0.8, 0.9, 1.0],  # Диапазон для выбора точек изменения\n",
    "    'yearly_seasonality': [True, 5, 10],  # True - авто, 5 или 10 для настройки\n",
    "    'weekly_seasonality': [True, 3, 5],  # True - авто, или точные значения\n",
    "    'daily_seasonality': [False, 10, 20],  # Добавляем дневную сезонность, если она есть\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],  # Режим сезонности\n",
    "    'growth': ['linear', 'discontinuous'],  # Режим роста\n",
    "    'n_lags': [0, 5, 10],  # Задержки для добавления автокорреляции\n",
    "    'ar_regularization': [0, 0.1, 0.5],  # Регуляризация для автокорреляции\n",
    "    'trend_reg': [0, 0.1, 0.5],  # Регуляризация для тренда\n",
    "    'seasonality_reg': [0, 0.1, 0.5],  # Регуляризация для сезонности\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19cf1-1a97-4d83-99be-ed50fd5d26ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Рассчет прогноза с гиперпараметрами Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb99a36-6ec1-4e7f-8ee6-00097126e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                              # +2 новых гипера\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Блок 1: Загрузка данных и предварительная обработка\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "data = data[(data['Дата'] >= '2023-01-01')]\n",
    "\n",
    "# Подготовка данных для модели NeuralProphet\n",
    "data = data.rename(columns={'Дата': 'ds', 'Номер Магазина': 'store', '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Блок 2: Загрузка гиперпараметров модели\n",
    "try:\n",
    "    model_params = pd.read_excel('best_model_params_bayesian.xlsx')\n",
    "except FileNotFoundError:\n",
    "    model_params = pd.DataFrame(columns=['store', 'n_changepoints', 'changepoints_range', 'yearly_seasonality', \n",
    "                                         'weekly_seasonality', 'seasonality_mode', 'trend_reg', 'seasonality_reg'])\n",
    "\n",
    "# Блок 3: Предпраздничные даты и исключенные магазины\n",
    "pre_holiday_dates = ['2025-02-22','2025-03-07','2025-05-08','2025-06-11','2025-04-20','2025-05-02','2025-05-03',\n",
    "                     '2024-12-28','2024-12-29','2024-12-30','2024-12-31','2025-12-28','2025-12-29','2025-12-30','2025-12-31']\n",
    "excluded_stores = [149, 155, 164, 111, 123, 136, 127, 151, 109]\n",
    "standard_stores = [187, 188]\n",
    "\n",
    "# Функция для прогнозирования для одного магазина\n",
    "def forecast_store(store):\n",
    "    if store in excluded_stores:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = data[data['store'] == store]\n",
    "    if len(store_data) < 2:\n",
    "        print(f'Пропускаем магазин {store} из-за недостатка данных')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = store_data.drop_duplicates(subset=['ds'])\n",
    "    store_data = store_data.drop(columns=['store'])\n",
    "\n",
    "    # Проверка, используется ли магазин в стандартных гиперпараметрах\n",
    "    if store in standard_stores:\n",
    "        model = NeuralProphet()\n",
    "    else:\n",
    "        params = model_params[model_params['store'] == store]\n",
    "        if params.empty:\n",
    "            print(f'Не найдены гиперпараметры для магазина {store}, пропускаем его')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=params['n_changepoints'].values[0],\n",
    "            changepoints_range=params['changepoints_range'].values[0],\n",
    "            yearly_seasonality=params['yearly_seasonality'].values[0],\n",
    "            weekly_seasonality=params['weekly_seasonality'].values[0],\n",
    "            seasonality_mode=params['seasonality_mode'].values[0],\n",
    "            trend_reg=params['trend_reg'].values[0],\n",
    "            seasonality_reg=params['seasonality_reg'].values[0]\n",
    "        )\n",
    "\n",
    "    model.fit(store_data, freq='D')\n",
    "    future = model.make_future_dataframe(store_data, periods=50)\n",
    "    forecast = model.predict(future)\n",
    "    forecast['store'] = store\n",
    "\n",
    "    for pre_holiday_date in pre_holiday_dates:\n",
    "        mask = forecast['ds'] == pd.to_datetime(pre_holiday_date)\n",
    "        forecast.loc[mask, 'yhat1'] *= 1.165\n",
    "\n",
    "    return forecast\n",
    "\n",
    "# Получение уникальных ID магазинов\n",
    "store_ids = data['store'].unique()\n",
    "\n",
    "# Параллельное прогнозирование для всех магазинов\n",
    "all_forecasts = Parallel(n_jobs=-1)(delayed(forecast_store)(store) for store in store_ids)\n",
    "\n",
    "# Объединение всех прогнозов в один DataFrame\n",
    "all_forecasts = pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "# Сохранение результатов прогноза в новом Excel-файле\n",
    "selected_columns = ['ds', 'store', 'yhat1']\n",
    "all_forecasts[selected_columns].to_excel('ФевральBayas.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513454f-6226-4aa7-a6c6-68cb8287c56a",
   "metadata": {},
   "source": [
    "# Рассчет прогноза с гиперпараметрами Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf966d7-b110-475c-b9c1-8bb0cdb02356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Блок 1: Загрузка данных и предварительная обработка\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "data = data[data['Дата'] >= '2023-01-01']\n",
    "\n",
    "data = data.rename(columns={'Дата': 'ds', 'Номер Магазина': 'store', '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Блок 2: Загрузка гиперпараметров модели\n",
    "try:\n",
    "    model_params = pd.read_excel('best_model_params_bo.xlsx')\n",
    "except FileNotFoundError:\n",
    "    model_params = pd.DataFrame(columns=['store', 'n_changepoints', 'changepoints_range', 'yearly_seasonality', \n",
    "                                         'weekly_seasonality', 'seasonality_mode', 'trend_reg', 'seasonality_reg',\n",
    "                                         'growth', 'n_lags', 'ar_reg'])\n",
    "\n",
    "# Блок 3: Предпраздничные даты и исключенные магазины\n",
    "pre_holiday_dates = ['2025-02-22', '2025-03-07', '2025-05-08', '2025-06-11', '2025-04-20', '2025-05-02', '2025-05-03',\n",
    "                     '2024-12-28', '2024-12-29', '2024-12-30', '2024-12-31', '2025-12-28', '2025-12-29', '2025-12-30', '2025-12-31']\n",
    "excluded_stores = [149, 155, 164, 111, 123, 136, 127, 151, 109]\n",
    "standard_stores = [187, 188]\n",
    "\n",
    "# Функция для прогнозирования одного магазина\n",
    "def forecast_store(store):\n",
    "    if store in excluded_stores:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = data[data['store'] == store]\n",
    "    if len(store_data) < 2:\n",
    "        print(f'Пропускаем магазин {store} из-за недостатка данных')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if store in standard_stores:\n",
    "        model = NeuralProphet()\n",
    "    else:\n",
    "        params = model_params[model_params['store'] == store]\n",
    "        if params.empty:\n",
    "            print(f'Не найдены гиперпараметры для магазина {store}, пропускаем его')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        params = params.to_dict('records')[0]  # Преобразуем в словарь\n",
    "\n",
    "        # Учитываем возможность числового значения для seasonality\n",
    "        yearly_seasonality = params['yearly_seasonality']\n",
    "        if yearly_seasonality not in [True, False]:\n",
    "            yearly_seasonality = int(yearly_seasonality)\n",
    "\n",
    "        weekly_seasonality = params['weekly_seasonality']\n",
    "        if weekly_seasonality not in [True, False]:\n",
    "            weekly_seasonality = int(weekly_seasonality)\n",
    "\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=int(params['n_changepoints']),\n",
    "            changepoints_range=float(params['changepoints_range']),\n",
    "            yearly_seasonality=yearly_seasonality,\n",
    "            weekly_seasonality=weekly_seasonality,\n",
    "            seasonality_mode=params['seasonality_mode'],\n",
    "            trend_reg=float(params['trend_reg']),\n",
    "            seasonality_reg=float(params['seasonality_reg']),\n",
    "            growth=params['growth'],\n",
    "            n_lags=int(params['n_lags']),\n",
    "            ar_reg=float(params['ar_reg'])  # Исправлено имя параметра\n",
    "        )\n",
    "\n",
    "    model.fit(store_data, freq='D')\n",
    "\n",
    "    # Создание будущих дат\n",
    "    future = model.make_future_dataframe(df=store_data, periods=50)\n",
    "\n",
    "    # Получение прогноза\n",
    "    forecast = model.predict(future)\n",
    "    forecast['store'] = store\n",
    "\n",
    "    # Корректировка предпраздничных дней\n",
    "    forecast['ds'] = pd.to_datetime(forecast['ds'])\n",
    "    forecast.loc[forecast['ds'].isin(pd.to_datetime(pre_holiday_dates)), 'yhat1'] *= 1.165\n",
    "\n",
    "    return forecast\n",
    "\n",
    "# Запуск прогнозирования\n",
    "store_ids = data['store'].unique()\n",
    "all_forecasts = Parallel(n_jobs=-1)(delayed(forecast_store)(store) for store in store_ids)\n",
    "\n",
    "# Объединение прогнозов\n",
    "all_forecasts = [f for f in all_forecasts if not f.empty]  # Убираем пустые DataFrame\n",
    "if len(all_forecasts) > 0:\n",
    "    final_forecast = pd.concat(all_forecasts, ignore_index=True)\n",
    "    final_forecast[['ds', 'store', 'yhat1']].to_excel('Февраль.xlsx', index=False)\n",
    "    print(\"Прогноз успешно сохранен в 'Февраль.xlsx'\")\n",
    "else:\n",
    "    print(\"Не удалось сформировать прогноз, все магазины исключены.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb59488-476f-443d-a20f-7067ae4888d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80e2ae-e322-4e98-9f58-dd1f9a986ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                     # График по всем магазинам\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных прогнозов и фактических продаж\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "\n",
    "# Переименование столбцов для удобства\n",
    "data = data.rename(columns={\n",
    "    'Дата': 'ds', \n",
    "    'Номер Магазина': 'store', \n",
    "    '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'\n",
    "})\n",
    "\n",
    "# Преобразование столбца 'y' в числовой формат\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Фильтрация данных начиная с 2024 года\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# Суммирование фактических данных по всем магазинам\n",
    "total_sales = data.groupby('ds').agg({'y': 'sum'}).reset_index()\n",
    "\n",
    "# Загрузка прогнозов\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx',sheet_name='Sheet1', index_col=None)  # Измени имя файла, если нужно\n",
    "all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']\n",
    "\n",
    "# Суммирование прогнозов по всем магазинам\n",
    "summed_forecasts = filtered_forecasts.groupby('ds').agg({'yhat1': 'sum'}).reset_index()  # Измени 'yhat' на 'yhat1'\n",
    "\n",
    "# Создание общего графика суммарного прогноза с фактическими данными\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Линия фактических продаж\n",
    "plt.plot(total_sales['ds'], total_sales['y'], label='Продажи', color='red', linewidth=2)\n",
    "\n",
    "# Линия суммарного прогноза\n",
    "plt.plot(summed_forecasts['ds'], summed_forecasts['yhat1'], label='Прогноз', color='blue', linestyle='--', linewidth=2)  # Измени 'yhat' на 'yhat1'\n",
    "\n",
    "# Настройка заголовка и меток осей\n",
    "plt.title('Динамика Продаж и Прогноза', fontsize=16)\n",
    "plt.xlabel('Понедельники', fontsize=14)\n",
    "plt.ylabel('Продажи в руб.', fontsize=14)\n",
    "\n",
    "# Отображение легенды\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Отображение сетки\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Улучшение форматирования осей\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Добавление разделителей тысяч для оси Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# Добавление меток начала каждой недели на ось X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Показ графика\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83adba-a49b-4da8-91f0-ec98e2665b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # График по выбранному магазину\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных прогнозов и фактических продаж\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "\n",
    "# Переименование столбцов для удобства\n",
    "data = data.rename(columns={\n",
    "    'Дата': 'ds', \n",
    "    'Номер Магазина': 'store', \n",
    "    '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'\n",
    "})\n",
    "\n",
    "# Преобразование столбца 'y' в числовой формат\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Фильтрация данных начиная с 2024 года\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# Фильтрация данных по выбранному магазину (например, магазин с ID 148)\n",
    "store_id = 152\n",
    "store_data = data[data['store'] == store_id]\n",
    "\n",
    "# Загрузка прогнозов\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx', index_col=None)\n",
    "\n",
    "# Вывод доступных столбцов для диагностики\n",
    "print(all_forecasts.columns)  # Добавлено для отладки\n",
    "\n",
    "# Проверка названия столбца 'ds'\n",
    "if 'ds' in all_forecasts.columns:\n",
    "    all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "else:\n",
    "    all_forecasts[' Дата'] = pd.to_datetime(all_forecasts[' Дата'])  # Измени имя, если нужно\n",
    "\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']  # Измените имя столбца при необходимости\n",
    "\n",
    "# Фильтрация прогнозов по выбранному магазину\n",
    "store_forecasts = filtered_forecasts[filtered_forecasts['store'] == store_id]\n",
    "\n",
    "# Создание графика прогноза с фактическими данными для выбранного магазина\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Линия фактических продаж\n",
    "plt.plot(store_data['ds'], store_data['y'], label='Продажи', color='red', linewidth=2)\n",
    "\n",
    "# Линия прогноза\n",
    "plt.plot(store_forecasts['ds'], store_forecasts['yhat1'], label='Прогноз', color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "# Настройка заголовка и меток осей\n",
    "plt.title(f'Динамика Продаж и Прогноза для магазина {store_id}', fontsize=16)\n",
    "plt.xlabel('Понедельники', fontsize=14)\n",
    "plt.ylabel('Продажи в руб.', fontsize=14)\n",
    "\n",
    "# Отображение легенды\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Отображение сетки\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Улучшение форматирования осей\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Добавление разделителей тысяч для оси Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# Добавление меток начала каждой недели на ось X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Показ графика\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c2219-4b29-4b05-aba6-a24177403069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MXNet тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5cb27-124b-4226-a3b0-50b14eee831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                  # МXNet на тест(не использовал. ошибка библы)\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Блок 1: Загрузка и подготовка данных\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/MXNet/Sales.csv', sep=';', low_memory=False)\n",
    "data['Дата'] = pd.to_datetime(data['Дата'], dayfirst=True)\n",
    "data = data[(data['Дата'] >= '2021-01-01')]\n",
    "\n",
    "# Подготовка данных\n",
    "data = data.rename(columns={'Дата': 'ds', 'Номер Магазина': 'store', '(Сутки).(Сумма продаж в фактических ценах реализации(валюта))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "data = data.drop_duplicates(subset=['store', 'ds'])\n",
    "\n",
    "# Параметры для MXNet\n",
    "num_hidden = 64  # Размер слоя скрытых нейронов\n",
    "num_layers = 2   # Количество слоев в RNN\n",
    "batch_size = 16  # Размер батча\n",
    "epochs = 10      # Количество эпох для обучения\n",
    "\n",
    "# Блок 2: Подготовка функции для создания датасетов\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences, labels = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = data[i:i + sequence_length]\n",
    "        label = data[i + sequence_length]\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Блок 3: Функция для подготовки данных каждого магазина\n",
    "def prepare_data_for_store(store_data):\n",
    "    store_data = store_data[['ds', 'y']].sort_values(by='ds')\n",
    "    store_data = store_data.set_index('ds')\n",
    "    return store_data['y'].values\n",
    "\n",
    "# Блок 4: Модель RNN для прогнозирования\n",
    "class SalesForecastingModel(nn.Block):\n",
    "    def __init__(self, num_hidden, num_layers, **kwargs):\n",
    "        super(SalesForecastingModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn.LSTM(num_hidden, num_layers, layout='NTC')\n",
    "        self.dense = nn.Dense(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x[:, -1, :])\n",
    "\n",
    "# Функция для обучения и прогнозирования\n",
    "def forecast_with_mxnet(store, data):\n",
    "    sequence_length = 30  # Период временного ряда\n",
    "    data = prepare_data_for_store(data[data['store'] == store])\n",
    "\n",
    "    if len(data) < sequence_length:\n",
    "        print(f'Пропускаем магазин {store} из-за недостатка данных')\n",
    "        return pd.DataFrame()  # Пропуск магазина с недостаточным объемом данных\n",
    "\n",
    "    train_sequences, train_labels = create_sequences(data, sequence_length)\n",
    "    train_sequences = mx.nd.array(train_sequences).reshape((-1, sequence_length, 1))\n",
    "    train_labels = mx.nd.array(train_labels).reshape((-1, 1))\n",
    "\n",
    "    model = SalesForecastingModel(num_hidden, num_layers)\n",
    "    model.initialize(mx.init.Xavier(), ctx=mx.cpu())\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 0.001})\n",
    "    loss_function = gluon.loss.L2Loss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cumulative_loss = 0\n",
    "        for i in range(0, len(train_sequences), batch_size):\n",
    "            batch_data = train_sequences[i:i + batch_size]\n",
    "            batch_labels = train_labels[i:i + batch_size]\n",
    "            with autograd.record():\n",
    "                predictions = model(batch_data)\n",
    "                loss = loss_function(predictions, batch_labels)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_data.shape[0])\n",
    "            cumulative_loss += mx.nd.sum(loss).asscalar()\n",
    "        print(f\"Эпоха {epoch + 1}, Потери: {cumulative_loss / len(train_sequences)}\")\n",
    "\n",
    "    # Прогнозирование на 30 дней вперед\n",
    "    last_sequence = mx.nd.array(data[-sequence_length:]).reshape((1, sequence_length, 1))\n",
    "    predictions = []\n",
    "    for _ in range(30):\n",
    "        next_pred = model(last_sequence)\n",
    "        predictions.append(next_pred.asscalar())\n",
    "        last_sequence = mx.nd.concat(last_sequence[:, 1:, :], next_pred.reshape((1, 1, 1)), dim=1)\n",
    "\n",
    "    # Форматирование результатов\n",
    "    forecast_dates = pd.date_range(start=data.index[-1], periods=45, freq='D')\n",
    "    forecast_df = pd.DataFrame({'ds': forecast_dates, 'yhat': predictions})\n",
    "    forecast_df['store'] = store\n",
    "    return forecast_df\n",
    "\n",
    "# Блок 5: Параллельное прогнозирование для всех магазинов\n",
    "store_ids = data['store'].unique()\n",
    "all_forecasts = Parallel(n_jobs=-1)(delayed(forecast_with_mxnet)(store, data) for store in store_ids)\n",
    "\n",
    "# Объединение всех прогнозов\n",
    "all_forecasts = pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "# Сохранение результатов\n",
    "selected_columns = ['ds', 'store', 'yhat']\n",
    "all_forecasts[selected_columns].to_excel('Forecast_MXNet.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
