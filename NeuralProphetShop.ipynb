{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2117a097-4a52-45b6-8ab8-d708caf8ae30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e56f9-3f80-4ca5-a535-7f6bbca41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                         #–í–∫–ª—é—á–∞–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e1055-9bc4-4b8b-9314-bc3449378c31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid search hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d39fc0-226e-4bfc-ba8d-2934e760c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                         #+ 2 –¥–æ–ø.–≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞\n",
    "from neuralprophet import NeuralProphet\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed  # –î–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "\n",
    "# –ë–ª–æ–∫ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data[(data['–î–∞—Ç–∞'] >= '2022-01-01')]\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏ NeuralProphet\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∫–æ–ª–æ–Ω–∫–µ 'ds' (–¥–∞—Ç—ã) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "data = data.drop_duplicates(subset=['store', 'ds'])\n",
    "\n",
    "# –ë–ª–æ–∫ 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ—Ç–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "n_changepoints = [5, 10, 20, 30]\n",
    "changepoints_range = [0.75, 0.85, 0.95]\n",
    "yearly_seasonality = [True, 5, 10]\n",
    "weekly_seasonality = [True, 3, 6]\n",
    "seasonality_mode = ['additive', 'multiplicative']\n",
    "trend_reg = [0.4]\n",
    "seasonality_reg = [0.4]\n",
    "\n",
    "# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 30 –¥–Ω–µ–π)\n",
    "min_data_points = 60\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "def calculate_best_params_for_store(store_id, store_data):\n",
    "    if len(store_data) < min_data_points:\n",
    "        print(f\"–ü—Ä–æ–ø—É—Å–∫ –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(store_data)} —Å—Ç—Ä–æ–∫)\")\n",
    "        return None\n",
    "    \n",
    "    best_accuracy = float('inf')  # –ù–∞—á–∞–ª—å–Ω–∞—è –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (–¥–ª—è MAE)\n",
    "    best_params = {}\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ\n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data = store_data[:train_size]\n",
    "    test_data = store_data[train_size:]\n",
    "    \n",
    "    # –ü–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    for n_cp, cp_range, yearly_seas, weekly_seas, seas_mode, t_reg, s_reg in product(\n",
    "        n_changepoints, changepoints_range, yearly_seasonality, weekly_seasonality, seasonality_mode, trend_reg, seasonality_reg\n",
    "    ):\n",
    "        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=n_cp,\n",
    "            changepoints_range=cp_range,\n",
    "            yearly_seasonality=yearly_seas,\n",
    "            weekly_seasonality=weekly_seas,\n",
    "            seasonality_mode=seas_mode,\n",
    "            trend_reg=t_reg,\n",
    "            seasonality_reg=s_reg\n",
    "            #device=device\n",
    "        )\n",
    "        \n",
    "        model.fit(train_data, freq='D')\n",
    "        \n",
    "        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        future = model.make_future_dataframe(test_data, periods=len(test_data))\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "        y_true = test_data['y'].values\n",
    "        y_pred = forecast['yhat1'].values[:len(test_data)]\n",
    "        accuracy = mean_absolute_error(y_true, y_pred)\n",
    "        \n",
    "        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        if accuracy < best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {\n",
    "                'store': store_id,\n",
    "                'n_changepoints': n_cp,\n",
    "                'changepoints_range': cp_range,\n",
    "                'yearly_seasonality': yearly_seas,\n",
    "                'weekly_seasonality': weekly_seas,\n",
    "                'seasonality_mode': seas_mode,\n",
    "                'trend_reg': t_reg,\n",
    "                'seasonality_reg': s_reg\n",
    "            }\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "stores = data['store'].unique()\n",
    "\n",
    "# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "best_params_list = Parallel(n_jobs=-1)(\n",
    "    delayed(calculate_best_params_for_store)(store_id, data[data['store'] == store_id][['ds', 'y']]) \n",
    "    for store_id in stores\n",
    ")\n",
    "\n",
    "# –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è (–µ—Å–ª–∏ –º–∞–≥–∞–∑–∏–Ω –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö)\n",
    "best_params_list = [params for params in best_params_list if params is not None]\n",
    "\n",
    "# –ë–ª–æ–∫ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ –≤ Excel —Ñ–∞–π–ª\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_model_params_all_stores+.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f49447-226d-4499-a847-839490ca4257",
   "metadata": {},
   "source": [
    "# Bayes optimization hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a0a8c-4893-4f85-9da2-e93261b673cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data[(data['–î–∞—Ç–∞'] >= '2023-01-01')]\n",
    "\n",
    "# üîπ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data = data.drop_duplicates(subset=['store', 'ds'])\n",
    "\n",
    "# üîπ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "min_data_points = 60\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def objective(trial, store_data, store_id):\n",
    "    if len(store_data) < min_data_points:\n",
    "        return float('inf')  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–≥–∞–∑–∏–Ω—ã —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–º –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    # –í—ã–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    n_changepoints = trial.suggest_int('n_changepoints', 5, 30)  \n",
    "    changepoints_range = trial.suggest_float('changepoints_range', 0.75, 0.95)\n",
    "    yearly_seasonality = trial.suggest_int('yearly_seasonality', 1, 20)  \n",
    "    weekly_seasonality = trial.suggest_int('weekly_seasonality', 1, 7)  \n",
    "    seasonality_mode = trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative'])\n",
    "    trend_reg = trial.suggest_float('trend_reg', 0.1, 1.0)\n",
    "    seasonality_reg = trial.suggest_float('seasonality_reg', 0.1, 1.0)\n",
    "    growth = trial.suggest_categorical('growth', ['linear', 'discontinuous'])\n",
    "    n_lags = trial.suggest_int('n_lags', 0, 30)\n",
    "\n",
    "    # üîπ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ar_reg –¢–û–õ–¨–ö–û –µ—Å–ª–∏ n_lags > 0\n",
    "    if n_lags > 0:\n",
    "        ar_reg = trial.suggest_float('ar_reg', 0.0, 1.0)\n",
    "    else:\n",
    "        ar_reg = None  # NeuralProphet –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç None\n",
    "\n",
    "    # üîπ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/test\n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data, test_data = store_data[:train_size], store_data[train_size:]\n",
    "\n",
    "    # üîπ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    model = NeuralProphet(\n",
    "        n_changepoints=n_changepoints,\n",
    "        changepoints_range=changepoints_range,\n",
    "        yearly_seasonality=yearly_seasonality,\n",
    "        weekly_seasonality=weekly_seasonality,\n",
    "        seasonality_mode=seasonality_mode,\n",
    "        trend_reg=trend_reg,\n",
    "        seasonality_reg=seasonality_reg,\n",
    "        growth=growth, \n",
    "        n_lags=n_lags, \n",
    "        ar_reg=ar_reg if ar_reg is not None else 0.0  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 0.0, –µ—Å–ª–∏ ar_reg –Ω–µ –∑–∞–¥–∞–Ω\n",
    "    )\n",
    "    model.fit(train_data, freq='D')\n",
    "\n",
    "    # üîπ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—É–¥—É—â–∏—Ö –¥–∞—Ç\n",
    "    future = model.make_future_dataframe(df=train_data, periods=len(test_data))\n",
    "\n",
    "    # üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # üîπ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "    if len(forecast) < len(test_data):\n",
    "        return float('inf')  # –ï—Å–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑ –∫–æ—Ä–æ—á–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é\n",
    "\n",
    "    # üîπ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "    y_true, y_pred = test_data['y'].values, forecast['yhat1'].values[:len(test_data)]\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É\n",
    "def optimize_for_store(store_id, store_data):\n",
    "    print(f\"üîÑ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}...\")\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, store_data, store_id), n_trials=50)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['store'] = store_id\n",
    "\n",
    "    print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}: {best_params}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "# üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "stores = data['store'].unique()\n",
    "\n",
    "# üî• –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "best_params_list = Parallel(n_jobs=-1)(\n",
    "    delayed(optimize_for_store)(store_id, data[data['store'] == store_id][['ds', 'y']]) for store_id in stores\n",
    ")\n",
    "\n",
    "# üîπ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_model_params_bo.xlsx', index=False)\n",
    "\n",
    "print(\"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ best_model_params_bo.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2082b-4a5b-4956-9234-981fcb17694f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b315fb1-b8b7-4fe8-aa09-80a9fad0f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52488 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–µ—Ä–µ–±–æ—Ä–∞.–¥–ª—è 1 –º–∞–≥–∞–∑–∏–Ω–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π 16 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –≤ –º–∏–Ω—É—Ç—É \n",
    "# –Ω–∞ –ø—Ä–æ—Ü–µ—Å–æ–æ—Ä–µ –±—É–¥–µ—Ç —Å—á–∏—Ç–∞—Ç—å 54 —á–∞—Å–∞...\n",
    "param_grid = {\n",
    "    'n_changepoints': [5, 10, 20],  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞\n",
    "    'changepoints_range': [0.8, 0.9, 1.0],  # –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "    'yearly_seasonality': [True, 5, 10],  # True - –∞–≤—Ç–æ, 5 –∏–ª–∏ 10 –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "    'weekly_seasonality': [True, 3, 5],  # True - –∞–≤—Ç–æ, –∏–ª–∏ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "    'daily_seasonality': [False, 10, 20],  # –î–æ–±–∞–≤–ª—è–µ–º –¥–Ω–µ–≤–Ω—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],  # –†–µ–∂–∏–º —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "    'growth': ['linear', 'discontinuous'],  # –†–µ–∂–∏–º —Ä–æ—Å—Ç–∞\n",
    "    'n_lags': [0, 5, 10],  # –ó–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "    'ar_regularization': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "    'trend_reg': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞\n",
    "    'seasonality_reg': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e19cf1-1a97-4d83-99be-ed50fd5d26ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –†–∞—Å—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb99a36-6ec1-4e7f-8ee6-00097126e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                              # +2 –Ω–æ–≤—ã—Ö –≥–∏–ø–µ—Ä–∞\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# –ë–ª–æ–∫ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data[(data['–î–∞—Ç–∞'] >= '2023-01-01')]\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏ NeuralProphet\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# –ë–ª–æ–∫ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "try:\n",
    "    model_params = pd.read_excel('best_model_params_bayesian.xlsx')\n",
    "except FileNotFoundError:\n",
    "    model_params = pd.DataFrame(columns=['store', 'n_changepoints', 'changepoints_range', 'yearly_seasonality', \n",
    "                                         'weekly_seasonality', 'seasonality_mode', 'trend_reg', 'seasonality_reg'])\n",
    "\n",
    "# –ë–ª–æ–∫ 3: –ü—Ä–µ–¥–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–∞—Ç—ã –∏ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã\n",
    "pre_holiday_dates = ['2025-02-22','2025-03-07','2025-05-08','2025-06-11','2025-04-20','2025-05-02','2025-05-03',\n",
    "                     '2024-12-28','2024-12-29','2024-12-30','2024-12-31','2025-12-28','2025-12-29','2025-12-30','2025-12-31']\n",
    "excluded_stores = [149, 155, 164, 111, 123, 136, 127, 151, 109]\n",
    "standard_stores = [187, 188]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "def forecast_store(store):\n",
    "    if store in excluded_stores:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = data[data['store'] == store]\n",
    "    if len(store_data) < 2:\n",
    "        print(f'–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–≥–∞–∑–∏–Ω {store} –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = store_data.drop_duplicates(subset=['ds'])\n",
    "    store_data = store_data.drop(columns=['store'])\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –º–∞–≥–∞–∑–∏–Ω –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö\n",
    "    if store in standard_stores:\n",
    "        model = NeuralProphet()\n",
    "    else:\n",
    "        params = model_params[model_params['store'] == store]\n",
    "        if params.empty:\n",
    "            print(f'–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=params['n_changepoints'].values[0],\n",
    "            changepoints_range=params['changepoints_range'].values[0],\n",
    "            yearly_seasonality=params['yearly_seasonality'].values[0],\n",
    "            weekly_seasonality=params['weekly_seasonality'].values[0],\n",
    "            seasonality_mode=params['seasonality_mode'].values[0],\n",
    "            trend_reg=params['trend_reg'].values[0],\n",
    "            seasonality_reg=params['seasonality_reg'].values[0]\n",
    "        )\n",
    "\n",
    "    model.fit(store_data, freq='D')\n",
    "    future = model.make_future_dataframe(store_data, periods=50)\n",
    "    forecast = model.predict(future)\n",
    "    forecast['store'] = store\n",
    "\n",
    "    for pre_holiday_date in pre_holiday_dates:\n",
    "        mask = forecast['ds'] == pd.to_datetime(pre_holiday_date)\n",
    "        forecast.loc[mask, 'yhat1'] *= 1.165\n",
    "\n",
    "    return forecast\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "store_ids = data['store'].unique()\n",
    "\n",
    "# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "all_forecasts = Parallel(n_jobs=-1)(delayed(forecast_store)(store) for store in store_ids)\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ –æ–¥–∏–Ω DataFrame\n",
    "all_forecasts = pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ –Ω–æ–≤–æ–º Excel-—Ñ–∞–π–ª–µ\n",
    "selected_columns = ['ds', 'store', 'yhat1']\n",
    "all_forecasts[selected_columns].to_excel('–§–µ–≤—Ä–∞–ª—åBayas.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513454f-6226-4aa7-a6c6-68cb8287c56a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –†–∞—Å—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf966d7-b110-475c-b9c1-8bb0cdb02356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# –ë–ª–æ–∫ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data[data['–î–∞—Ç–∞'] >= '2023-01-01']\n",
    "\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# –ë–ª–æ–∫ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "try:\n",
    "    model_params = pd.read_excel('best_model_params_bo.xlsx')\n",
    "except FileNotFoundError:\n",
    "    model_params = pd.DataFrame(columns=['store', 'n_changepoints', 'changepoints_range', 'yearly_seasonality', \n",
    "                                         'weekly_seasonality', 'seasonality_mode', 'trend_reg', 'seasonality_reg',\n",
    "                                         'growth', 'n_lags', 'ar_reg'])\n",
    "\n",
    "# –ë–ª–æ–∫ 3: –ü—Ä–µ–¥–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–∞—Ç—ã –∏ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã\n",
    "pre_holiday_dates = ['2025-02-22', '2025-03-07', '2025-05-08', '2025-06-11', '2025-04-20', '2025-05-02', '2025-05-03',\n",
    "                     '2024-12-28', '2024-12-29', '2024-12-30', '2024-12-31', '2025-12-28', '2025-12-29', '2025-12-30', '2025-12-31']\n",
    "excluded_stores = [149, 155, 164, 111, 123, 136, 127, 151, 109]\n",
    "standard_stores = [187, 188]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "def forecast_store(store):\n",
    "    if store in excluded_stores:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = data[data['store'] == store]\n",
    "    if len(store_data) < 2:\n",
    "        print(f'–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–≥–∞–∑–∏–Ω {store} –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if store in standard_stores:\n",
    "        model = NeuralProphet()\n",
    "    else:\n",
    "        params = model_params[model_params['store'] == store]\n",
    "        if params.empty:\n",
    "            print(f'–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        params = params.to_dict('records')[0]  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "\n",
    "        # –£—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —á–∏—Å–ª–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è seasonality\n",
    "        yearly_seasonality = params['yearly_seasonality']\n",
    "        if yearly_seasonality not in [True, False]:\n",
    "            yearly_seasonality = int(yearly_seasonality)\n",
    "\n",
    "        weekly_seasonality = params['weekly_seasonality']\n",
    "        if weekly_seasonality not in [True, False]:\n",
    "            weekly_seasonality = int(weekly_seasonality)\n",
    "\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=int(params['n_changepoints']),\n",
    "            changepoints_range=float(params['changepoints_range']),\n",
    "            yearly_seasonality=yearly_seasonality,\n",
    "            weekly_seasonality=weekly_seasonality,\n",
    "            seasonality_mode=params['seasonality_mode'],\n",
    "            trend_reg=float(params['trend_reg']),\n",
    "            seasonality_reg=float(params['seasonality_reg']),\n",
    "            growth=params['growth'],\n",
    "            n_lags=int(params['n_lags']),\n",
    "            ar_reg=float(params['ar_reg'])  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞\n",
    "        )\n",
    "\n",
    "    model.fit(store_data, freq='D')\n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö –¥–∞—Ç\n",
    "    future = model.make_future_dataframe(df=store_data, periods=50)\n",
    "\n",
    "    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "    forecast = model.predict(future)\n",
    "    forecast['store'] = store\n",
    "\n",
    "    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø—Ä–µ–¥–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö –¥–Ω–µ–π\n",
    "    forecast['ds'] = pd.to_datetime(forecast['ds'])\n",
    "    forecast.loc[forecast['ds'].isin(pd.to_datetime(pre_holiday_dates)), 'yhat1'] *= 1.165\n",
    "\n",
    "    return forecast\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "store_ids = data['store'].unique()\n",
    "all_forecasts = Parallel(n_jobs=-1)(delayed(forecast_store)(store) for store in store_ids)\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "all_forecasts = [f for f in all_forecasts if not f.empty]  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ DataFrame\n",
    "if len(all_forecasts) > 0:\n",
    "    final_forecast = pd.concat(all_forecasts, ignore_index=True)\n",
    "    final_forecast[['ds', 'store', 'yhat1']].to_excel('–§–µ–≤—Ä–∞–ª—å.xlsx', index=False)\n",
    "    print(\"–ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ '–§–µ–≤—Ä–∞–ª—å.xlsx'\")\n",
    "else:\n",
    "    print(\"–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑, –≤—Å–µ –º–∞–≥–∞–∑–∏–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω—ã.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb59488-476f-443d-a20f-7067ae4888d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –ì—Ä–∞—Ñ–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80e2ae-e322-4e98-9f58-dd1f9a986ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                     # –ì—Ä–∞—Ñ–∏–∫ –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "data = data.rename(columns={\n",
    "    '–î–∞—Ç–∞': 'ds', \n",
    "    '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', \n",
    "    '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'\n",
    "})\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'y' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞—á–∏–Ω–∞—è —Å 2024 –≥–æ–¥–∞\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "total_sales = data.groupby('ds').agg({'y': 'sum'}).reset_index()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx',sheet_name='Sheet1', index_col=None)  # –ò–∑–º–µ–Ω–∏ –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']\n",
    "\n",
    "# –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "summed_forecasts = filtered_forecasts.groupby('ds').agg({'yhat1': 'sum'}).reset_index()  # –ò–∑–º–µ–Ω–∏ 'yhat' –Ω–∞ 'yhat1'\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "plt.plot(total_sales['ds'], total_sales['y'], label='–ü—Ä–æ–¥–∞–∂–∏', color='red', linewidth=2)\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "plt.plot(summed_forecasts['ds'], summed_forecasts['yhat1'], label='–ü—Ä–æ–≥–Ω–æ–∑', color='blue', linestyle='--', linewidth=2)  # –ò–∑–º–µ–Ω–∏ 'yhat' –Ω–∞ 'yhat1'\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –º–µ—Ç–æ–∫ –æ—Å–µ–π\n",
    "plt.title('–î–∏–Ω–∞–º–∏–∫–∞ –ü—Ä–æ–¥–∞–∂ –∏ –ü—Ä–æ–≥–Ω–æ–∑–∞', fontsize=16)\n",
    "plt.xlabel('–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∏', fontsize=14)\n",
    "plt.ylabel('–ü—Ä–æ–¥–∞–∂–∏ –≤ —Ä—É–±.', fontsize=14)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–µ–≥–µ–Ω–¥—ã\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–µ—Ç–∫–∏\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Å–µ–π\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á –¥–ª—è –æ—Å–∏ Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –Ω–∞—á–∞–ª–∞ –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏ –Ω–∞ –æ—Å—å X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# –ü–æ–∫–∞–∑ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83adba-a49b-4da8-91f0-ec98e2665b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # –ì—Ä–∞—Ñ–∏–∫ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "data = data.rename(columns={\n",
    "    '–î–∞—Ç–∞': 'ds', \n",
    "    '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', \n",
    "    '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'\n",
    "})\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'y' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞—á–∏–Ω–∞—è —Å 2024 –≥–æ–¥–∞\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–∞–≥–∞–∑–∏–Ω —Å ID 148)\n",
    "store_id = 152\n",
    "store_data = data[data['store'] == store_id]\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx', index_col=None)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "print(all_forecasts.columns)  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞ 'ds'\n",
    "if 'ds' in all_forecasts.columns:\n",
    "    all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "else:\n",
    "    all_forecasts[' –î–∞—Ç–∞'] = pd.to_datetime(all_forecasts[' –î–∞—Ç–∞'])  # –ò–∑–º–µ–Ω–∏ –∏–º—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']  # –ò–∑–º–µ–Ω–∏—Ç–µ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É\n",
    "store_forecasts = filtered_forecasts[filtered_forecasts['store'] == store_id]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "plt.plot(store_data['ds'], store_data['y'], label='–ü—Ä–æ–¥–∞–∂–∏', color='red', linewidth=2)\n",
    "\n",
    "# –õ–∏–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "plt.plot(store_forecasts['ds'], store_forecasts['yhat1'], label='–ü—Ä–æ–≥–Ω–æ–∑', color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –º–µ—Ç–æ–∫ –æ—Å–µ–π\n",
    "plt.title(f'–î–∏–Ω–∞–º–∏–∫–∞ –ü—Ä–æ–¥–∞–∂ –∏ –ü—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}', fontsize=16)\n",
    "plt.xlabel('–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∏', fontsize=14)\n",
    "plt.ylabel('–ü—Ä–æ–¥–∞–∂–∏ –≤ —Ä—É–±.', fontsize=14)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–µ–≥–µ–Ω–¥—ã\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–µ—Ç–∫–∏\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Å–µ–π\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á –¥–ª—è –æ—Å–∏ Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –Ω–∞—á–∞–ª–∞ –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏ –Ω–∞ –æ—Å—å X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# –ü–æ–∫–∞–∑ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
