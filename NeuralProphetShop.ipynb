{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2117a097-4a52-45b6-8ab8-d708caf8ae30",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e56f9-3f80-4ca5-a535-7f6bbca41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                         #–í–∫–ª—é—á–∞–µ–º –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—É –µ—Å–ª–∏ –µ—Å—Ç—å\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04399dc9-f912-408b-9e97-75f0d0c33f0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Bayesian  optimization hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32a000-faef-4cb8-b92f-f0627ebcb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data.rename(columns={\n",
    "    '–î–∞—Ç–∞': 'ds',\n",
    "    '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store',\n",
    "    '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'\n",
    "})\n",
    "data['y'] = data['y'].astype(str).str.replace(',', '.').astype(float)\n",
    "data = data.drop_duplicates(subset=['store', 'ds']).dropna()\n",
    "data = data.sort_values(by=['store', 'ds']).reset_index(drop=True)\n",
    "data = data[data['ds'] >= '2023-01-01']\n",
    "\n",
    "# üîπ –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "store_groups = data.groupby('store')\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def objective(trial, store_data):\n",
    "    if len(store_data) < 60:\n",
    "        return float('inf')\n",
    "    \n",
    "    params = {\n",
    "        'n_changepoints': trial.suggest_int('n_changepoints', 5, 35),\n",
    "        'changepoints_range': trial.suggest_float('changepoints_range', 0.8, 0.95),\n",
    "        'yearly_seasonality': trial.suggest_int('yearly_seasonality', 1, 20),\n",
    "        'weekly_seasonality': trial.suggest_int('weekly_seasonality', 1, 7),\n",
    "        'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "        'trend_reg': trial.suggest_float('trend_reg', 0.1, 1.0),\n",
    "        'seasonality_reg': trial.suggest_float('seasonality_reg', 0.01, 1.0),\n",
    "    }\n",
    "    \n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data, test_data = store_data[:train_size], store_data[train_size:]\n",
    "    if len(test_data) == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    train_data = train_data[['ds', 'y']]\n",
    "    test_data = test_data[['ds', 'y']]\n",
    "    \n",
    "    model = NeuralProphet(**params, drop_missing=True)\n",
    "    model.fit(train_data, freq='D')\n",
    "    \n",
    "    future = model.make_future_dataframe(df=train_data, periods=len(test_data))\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    if forecast.empty or len(forecast) < len(test_data):\n",
    "        return float('inf')\n",
    "    \n",
    "    mae = mean_absolute_error(test_data['y'].values, forecast['yhat1'].values[:len(test_data)])\n",
    "    return mae\n",
    "\n",
    "# üî• –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "def optimize_for_store(store_id, store_data):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, store_data), n_trials=100)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    best_params['store'] = store_id\n",
    "    best_params['cv_score'] = study.best_value\n",
    "    return best_params\n",
    "\n",
    "# üî• –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n",
    "best_params_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(optimize_for_store)(store_id, store_data) for store_id, store_data in store_groups\n",
    ")\n",
    "\n",
    "# üîπ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_params.xlsx', index=False)\n",
    "\n",
    "print(\"‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655150a-20b2-4026-848d-f5586a583a56",
   "metadata": {},
   "source": [
    "# –ü–ª—é—Å CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de0a03-f653-421e-bcf6-b925641c3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# üî• –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor' if torch.cuda.is_available() else 'torch.FloatTensor')\n",
    "print(f\"üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "# ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].astype(str).str.replace(',', '.').astype(float)\n",
    "data = data.drop_duplicates(subset=['store', 'ds']).dropna()\n",
    "data = data.sort_values(by=['store', 'ds']).reset_index(drop=True)\n",
    "data = data[data['ds'] >= '2023-01-01']\n",
    "\n",
    "# üîπ –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "store_groups = data.groupby('store')\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def objective(trial, store_data):\n",
    "    if len(store_data) < 60:\n",
    "        return float('inf')\n",
    "\n",
    "    params = {\n",
    "        'n_changepoints': trial.suggest_int('n_changepoints', 5, 35),\n",
    "        'changepoints_range': trial.suggest_float('changepoints_range', 0.8, 0.95),\n",
    "        'yearly_seasonality': trial.suggest_int('yearly_seasonality', 1, 20),\n",
    "        'weekly_seasonality': trial.suggest_int('weekly_seasonality', 1, 7),\n",
    "        'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "        'trend_reg': trial.suggest_float('trend_reg', 0.1, 1.0),\n",
    "        'seasonality_reg': trial.suggest_float('seasonality_reg', 0.01, 1.0),\n",
    "        'learning_rate': 0.01,  # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "        'batch_size': 256,  # ‚úÖ –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "    }\n",
    "\n",
    "    train_size = int(len(store_data) * 0.8)\n",
    "    train_data, test_data = store_data[:train_size], store_data[train_size:]\n",
    "    if len(test_data) == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    train_data = train_data[['ds', 'y']]\n",
    "    test_data = test_data[['ds', 'y']]\n",
    "\n",
    "    # ‚úÖ –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å (—É–±—Ä–∞–ª–∏ device, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU –≤–Ω—É—Ç—Ä–∏ PyTorch)\n",
    "    model = NeuralProphet(**params)\n",
    "    model.fit(train_data, freq='D')\n",
    "\n",
    "    # ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "    future = model.make_future_dataframe(df=train_data, periods=len(test_data))\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    if forecast.empty or len(forecast) < len(test_data):\n",
    "        return float('inf')\n",
    "\n",
    "    mae = mean_absolute_error(test_data['y'].values, forecast['yhat1'].values[:len(test_data)])\n",
    "    return mae\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "def optimize_for_store(store_id, store_data):\n",
    "    print(f\"üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id} –Ω–∞—á–∞–ª–∞—Å—å...\")\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, store_data), n_trials=100)  # ‚ö° –£–≤–µ–ª–∏—á–µ–Ω–æ —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['store'] = store_id\n",
    "    best_params['cv_score'] = study.best_value\n",
    "\n",
    "    print(f\"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}!\")\n",
    "    return best_params\n",
    "\n",
    "# üî• –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å `loky`\n",
    "best_params_list = Parallel(n_jobs=-1, verbose=10, backend=\"loky\")(\n",
    "    delayed(optimize_for_store)(store_id, store_data) for store_id, store_data in store_groups\n",
    ")\n",
    "\n",
    "# üîπ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_params.xlsx', index=False)\n",
    "\n",
    "print(\"‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a3c9d-7287-49d2-acb4-f0962357adc1",
   "metadata": {},
   "source": [
    "# –ì–∏–ø–µ—Ä—ã –ü–ª—é—Å –ö—É–¥–∞ –ø–ª—é—Å –∫—Ä–æ—Å—Å –≤–∞–ª–∏–¥–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cd5d7-9fb2-4f5d-b71f-63039354184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\bondarenkovv\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 63.0min\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# üî• –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor' if torch.cuda.is_available() else 'torch.FloatTensor')\n",
    "print(f\"üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "# ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].astype(str).str.replace(',', '.').astype(float)\n",
    "data = data.drop_duplicates(subset=['store', 'ds']).dropna()\n",
    "data = data.sort_values(by=['store', 'ds']).reset_index(drop=True)\n",
    "data = data[data['ds'] >= '2023-01-01']\n",
    "\n",
    "# üîπ –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "store_groups = data.groupby('store')\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\n",
    "def objective(trial, store_data):\n",
    "    if len(store_data) < 60:\n",
    "        return float('inf')\n",
    "\n",
    "    params = {\n",
    "        'n_changepoints': trial.suggest_int('n_changepoints', 5, 35),\n",
    "        'changepoints_range': trial.suggest_float('changepoints_range', 0.8, 0.95),\n",
    "        'yearly_seasonality': trial.suggest_int('yearly_seasonality', 1, 20),\n",
    "        'weekly_seasonality': trial.suggest_int('weekly_seasonality', 1, 7),\n",
    "        'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
    "        'trend_reg': trial.suggest_float('trend_reg', 0.1, 1.0),\n",
    "        'seasonality_reg': trial.suggest_float('seasonality_reg', 0.01, 1.0),\n",
    "        'learning_rate': 0.01,  # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "        'batch_size': 256,  # ‚úÖ –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3)  # ‚úÖ 3 —Ñ–æ–ª–¥–∞\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, test_idx in tscv.split(store_data):\n",
    "        train_data, test_data = store_data.iloc[train_idx], store_data.iloc[test_idx]\n",
    "        \n",
    "        if len(test_data) == 0:\n",
    "            continue\n",
    "\n",
    "        train_data = train_data[['ds', 'y']]\n",
    "        test_data = test_data[['ds', 'y']]\n",
    "\n",
    "        # ‚úÖ –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏\n",
    "        model = NeuralProphet(**params)\n",
    "        model.fit(train_data, freq='D')\n",
    "\n",
    "        # ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "        future = model.make_future_dataframe(df=train_data, periods=len(test_data))\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        if forecast.empty or len(forecast) < len(test_data):\n",
    "            continue\n",
    "\n",
    "        mae = mean_absolute_error(test_data['y'].values, forecast['yhat1'].values[:len(test_data)])\n",
    "        scores.append(mae)\n",
    "\n",
    "    return sum(scores) / len(scores) if scores else float('inf')\n",
    "\n",
    "# üî• –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "def optimize_for_store(store_id, store_data):\n",
    "    print(f\"üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id} –Ω–∞—á–∞–ª–∞—Å—å...\")\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, store_data), n_trials=100)  # ‚ö° 100 –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params['store'] = store_id\n",
    "    best_params['cv_score'] = study.best_value\n",
    "\n",
    "    print(f\"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}!\")\n",
    "    return best_params\n",
    "\n",
    "# üî• –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å `loky`\n",
    "best_params_list = Parallel(n_jobs=-1, verbose=10, backend=\"loky\")(\n",
    "    delayed(optimize_for_store)(store_id, store_data) for store_id, store_data in store_groups\n",
    ")\n",
    "\n",
    "# üîπ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "best_params_df.to_excel('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/best_params.xlsx', index=False)\n",
    "\n",
    "print(\"‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b0064-5f05-4315-b49a-61336555a7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936af61b-69d8-4482-b9ff-f58b7f31e26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e317aaf-273c-4a50-b7fc-8a070446ab3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3638499-9969-40a7-80fe-6223457be920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c2082b-4a5b-4956-9234-981fcb17694f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b315fb1-b8b7-4fe8-aa09-80a9fad0f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 52488 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–µ—Ä–µ–±–æ—Ä–∞.–¥–ª—è 1 –º–∞–≥–∞–∑–∏–Ω–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –ø–∞—Ä–∞–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π 16 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –≤ –º–∏–Ω—É—Ç—É \n",
    "# –Ω–∞ –ø—Ä–æ—Ü–µ—Å–æ–æ—Ä–µ –±—É–¥–µ—Ç —Å—á–∏—Ç–∞—Ç—å 54 —á–∞—Å–∞...\n",
    "param_grid = {\n",
    "    'n_changepoints': [5, 10, 20],  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞\n",
    "    'changepoints_range': [0.8, 0.9, 1.0],  # –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–æ—á–µ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "    'yearly_seasonality': [True, 5, 10],  # True - –∞–≤—Ç–æ, 5 –∏–ª–∏ 10 –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "    'weekly_seasonality': [True, 3, 5],  # True - –∞–≤—Ç–æ, –∏–ª–∏ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "    'daily_seasonality': [False, 10, 20],  # –î–æ–±–∞–≤–ª—è–µ–º –¥–Ω–µ–≤–Ω—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],  # –†–µ–∂–∏–º —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "    'growth': ['linear', 'discontinuous'],  # –†–µ–∂–∏–º —Ä–æ—Å—Ç–∞\n",
    "    'n_lags': [0, 5, 10],  # –ó–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "    'ar_regularization': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n",
    "    'trend_reg': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞\n",
    "    'seasonality_reg': [0, 0.1, 0.5],  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695f3cf-0b5c-4060-864d-c97b6a801b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –†–∞—Å—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ Bayesian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e56bd0-059a-4850-a089-228613b969df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# –ë–ª–æ–∫ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "data = data[(data['–î–∞—Ç–∞'] >= '2023-01-01')]\n",
    "\n",
    "data = data.rename(columns={'–î–∞—Ç–∞': 'ds', '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'})\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# –ë–ª–æ–∫ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "try:\n",
    "    model_params = pd.read_excel('best_model_params_cv1.xlsx')\n",
    "except FileNotFoundError:\n",
    "    model_params = pd.DataFrame(columns=['store', 'n_changepoints', 'changepoints_range', 'yearly_seasonality', \n",
    "                                         'weekly_seasonality', 'seasonality_mode', 'trend_reg', 'seasonality_reg', 'monthly_seasonality'])\n",
    "\n",
    "# –ë–ª–æ–∫ 3: –ü—Ä–µ–¥–ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–∞—Ç—ã –∏ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã\n",
    "pre_holiday_dates = ['2025-02-22', '2025-03-07', '2025-05-08', '2025-06-11', '2025-04-20', '2025-05-02', '2025-05-03',\n",
    "                     '2024-12-28', '2024-12-29', '2024-12-30', '2024-12-31', '2025-12-28', '2025-12-29', '2025-12-30', '2025-12-31']\n",
    "excluded_stores = [149, 155, 164, 111, 123, 136, 127, 151, 109]\n",
    "standard_stores = [187, 188]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "def forecast_store(store):\n",
    "    if store in excluded_stores:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = data[data['store'] == store]\n",
    "    if len(store_data) < 2:\n",
    "        print(f'–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–≥–∞–∑–∏–Ω {store} –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    store_data = store_data.drop_duplicates(subset=['ds'])\n",
    "    store_data = store_data.drop(columns=['store'])\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –º–∞–≥–∞–∑–∏–Ω –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö\n",
    "    if store in standard_stores:\n",
    "        model = NeuralProphet()\n",
    "    else:\n",
    "        params = model_params[model_params['store'] == store]\n",
    "        if params.empty:\n",
    "            print(f'–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        model = NeuralProphet(\n",
    "            n_changepoints=int(params['n_changepoints'].values[0]),\n",
    "            changepoints_range=params['changepoints_range'].values[0],\n",
    "            yearly_seasonality=params['yearly_seasonality'].values[0],\n",
    "            weekly_seasonality=params['weekly_seasonality'].values[0],\n",
    "            seasonality_mode=params['seasonality_mode'].values[0],\n",
    "            trend_reg=params['trend_reg'].values[0],\n",
    "            seasonality_reg=params['seasonality_reg'].values[0]\n",
    "        )\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Å—è—á–Ω—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å\n",
    "        if 'monthly_seasonality' in params.columns:\n",
    "            model.add_seasonality(name='monthly', period=30.4, fourier_order=int(params['monthly_seasonality'].values[0]))\n",
    "\n",
    "    model.fit(store_data, freq='D')\n",
    "    future = model.make_future_dataframe(store_data, periods=50)\n",
    "    forecast = model.predict(future)\n",
    "    forecast['store'] = store\n",
    "\n",
    "    for pre_holiday_date in pre_holiday_dates:\n",
    "        mask = forecast['ds'] == pd.to_datetime(pre_holiday_date)\n",
    "        forecast.loc[mask, 'yhat1'] *= 1.165\n",
    "\n",
    "    return forecast\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "store_ids = data['store'].unique()\n",
    "\n",
    "# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤\n",
    "all_forecasts = Parallel(n_jobs=-1, verbose=10)(delayed(forecast_store)(store) for store in store_ids)\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ –æ–¥–∏–Ω DataFrame\n",
    "all_forecasts = pd.concat(all_forecasts, ignore_index=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ –Ω–æ–≤–æ–º Excel-—Ñ–∞–π–ª–µ\n",
    "selected_columns = ['ds', 'store', 'yhat1']\n",
    "all_forecasts[selected_columns].to_excel('–§–µ–≤—Ä–∞–ª—åbest_model_params_cv1.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb59488-476f-443d-a20f-7067ae4888d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# –ì—Ä–∞—Ñ–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80e2ae-e322-4e98-9f58-dd1f9a986ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                     # –ì—Ä–∞—Ñ–∏–∫ –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "data = data.rename(columns={\n",
    "    '–î–∞—Ç–∞': 'ds', \n",
    "    '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', \n",
    "    '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'\n",
    "})\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'y' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞—á–∏–Ω–∞—è —Å 2024 –≥–æ–¥–∞\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "total_sales = data.groupby('ds').agg({'y': 'sum'}).reset_index()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx',sheet_name='Sheet1', index_col=None)  # –ò–∑–º–µ–Ω–∏ –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']\n",
    "\n",
    "# –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –≤—Å–µ–º –º–∞–≥–∞–∑–∏–Ω–∞–º\n",
    "summed_forecasts = filtered_forecasts.groupby('ds').agg({'yhat1': 'sum'}).reset_index()  # –ò–∑–º–µ–Ω–∏ 'yhat' –Ω–∞ 'yhat1'\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "plt.plot(total_sales['ds'], total_sales['y'], label='–ü—Ä–æ–¥–∞–∂–∏', color='red', linewidth=2)\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Å—É–º–º–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "plt.plot(summed_forecasts['ds'], summed_forecasts['yhat1'], label='–ü—Ä–æ–≥–Ω–æ–∑', color='blue', linestyle='--', linewidth=2)  # –ò–∑–º–µ–Ω–∏ 'yhat' –Ω–∞ 'yhat1'\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –º–µ—Ç–æ–∫ –æ—Å–µ–π\n",
    "plt.title('–î–∏–Ω–∞–º–∏–∫–∞ –ü—Ä–æ–¥–∞–∂ –∏ –ü—Ä–æ–≥–Ω–æ–∑–∞', fontsize=16)\n",
    "plt.xlabel('–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∏', fontsize=14)\n",
    "plt.ylabel('–ü—Ä–æ–¥–∞–∂–∏ –≤ —Ä—É–±.', fontsize=14)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–µ–≥–µ–Ω–¥—ã\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–µ—Ç–∫–∏\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Å–µ–π\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á –¥–ª—è –æ—Å–∏ Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –Ω–∞—á–∞–ª–∞ –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏ –Ω–∞ –æ—Å—å X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# –ü–æ–∫–∞–∑ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83adba-a49b-4da8-91f0-ec98e2665b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # –ì—Ä–∞—Ñ–∏–∫ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "data = pd.read_csv('C:/Users/bondarenKovv/Desktop/Python/NeuralProphet/Magazin/Sales.csv', sep=';', low_memory=False)\n",
    "data['–î–∞—Ç–∞'] = pd.to_datetime(data['–î–∞—Ç–∞'], dayfirst=True)\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "data = data.rename(columns={\n",
    "    '–î–∞—Ç–∞': 'ds', \n",
    "    '–ù–æ–º–µ—Ä –ú–∞–≥–∞–∑–∏–Ω–∞': 'store', \n",
    "    '(–°—É—Ç–∫–∏).(–°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –≤ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω–∞—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏(–≤–∞–ª—é—Ç–∞))': 'y'\n",
    "})\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ 'y' –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç\n",
    "data['y'] = data['y'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞—á–∏–Ω–∞—è —Å 2024 –≥–æ–¥–∞\n",
    "data = data[data['ds'] >= '2023-12-01']\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–∞–≥–∞–∑–∏–Ω —Å ID 148)\n",
    "store_id = 152\n",
    "store_data = data[data['store'] == store_id]\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n",
    "all_forecasts = pd.read_excel('Forecast_NeuralProphet_with_reg.xlsx', index_col=None)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "print(all_forecasts.columns)  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–∞ 'ds'\n",
    "if 'ds' in all_forecasts.columns:\n",
    "    all_forecasts['ds'] = pd.to_datetime(all_forecasts['ds'])\n",
    "else:\n",
    "    all_forecasts[' –î–∞—Ç–∞'] = pd.to_datetime(all_forecasts[' –î–∞—Ç–∞'])  # –ò–∑–º–µ–Ω–∏ –∏–º—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "\n",
    "filtered_forecasts = all_forecasts[all_forecasts['ds'] >= '2023-12-01']  # –ò–∑–º–µ–Ω–∏—Ç–µ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–∞–≥–∞–∑–∏–Ω—É\n",
    "store_forecasts = filtered_forecasts[filtered_forecasts['store'] == store_id]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# –õ–∏–Ω–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–∞–∂\n",
    "plt.plot(store_data['ds'], store_data['y'], label='–ü—Ä–æ–¥–∞–∂–∏', color='red', linewidth=2)\n",
    "\n",
    "# –õ–∏–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "plt.plot(store_forecasts['ds'], store_forecasts['yhat1'], label='–ü—Ä–æ–≥–Ω–æ–∑', color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –º–µ—Ç–æ–∫ –æ—Å–µ–π\n",
    "plt.title(f'–î–∏–Ω–∞–º–∏–∫–∞ –ü—Ä–æ–¥–∞–∂ –∏ –ü—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞ {store_id}', fontsize=16)\n",
    "plt.xlabel('–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∏', fontsize=14)\n",
    "plt.ylabel('–ü—Ä–æ–¥–∞–∂–∏ –≤ —Ä—É–±.', fontsize=14)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–µ–≥–µ–Ω–¥—ã\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–µ—Ç–∫–∏\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Å–µ–π\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á –¥–ª—è –æ—Å–∏ Y\n",
    "plt.gca().get_yaxis().set_major_formatter(plt.matplotlib.ticker.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –Ω–∞—á–∞–ª–∞ –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏ –Ω–∞ –æ—Å—å X\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# –ü–æ–∫–∞–∑ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
